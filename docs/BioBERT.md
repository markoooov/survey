# BioBERT: a pre-trained biomedical language representation model for biomedical text mining

Wikipedia, BooksCorpusで学習したBERTをさらに、医療関係の大規模なテキスト(PubMed, PMC)で学習したモデルBioBERTを提案。医療ドメインのNER, Relation extraction, Question answeringで、BERTを上回る性能を達成し、医療ドメインテキストによる事前学習の有用性を示した。

![biobert](https://user-images.githubusercontent.com/53220859/62830928-faf14700-bc51-11e9-82e8-4770b77891cb.png)

※ 図は元論文から引用

<br>

## 

## 文献情報

- 著者: Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So and Jaewoo Kang
- リンク: [https://arxiv.org/abs/1901.08746](https://arxiv.org/abs/1901.08746)